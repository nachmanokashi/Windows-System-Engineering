# server/scripts/import_news.py
"""
×¡×§×¨×™×¤×˜ ×œ×™×™×‘×•× ××××¨×™× ×-News API
"""

import sys
import os

# ×”×•×¡×£ ××ª ×ª×™×§×™×™×ª ×”-server ×œ-path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from sqlalchemy.orm import Session
from app.core.db import SessionLocal
from app.mvc.models.articles.article_entity import Article
from app.gateways.news_api_gateway import NewsAPIGateway


def import_articles_from_category(
    db: Session, 
    category: str, 
    limit: int = 10
) -> int:
    """×™×™×‘× ××××¨×™× ××§×˜×’×•×¨×™×” ××¡×•×™××ª"""
    gateway = NewsAPIGateway()
    
    try:
        print(f"\nğŸ“¥ ××™×™×‘× ××××¨×™× ××§×˜×’×•×¨×™×”: {category}")
        articles = gateway.get_top_headlines(category=category, page_size=limit)
        
        added_count = 0
        skipped_count = 0
        
        for article_data in articles:
            # ×‘×“×•×§ ×× ×”××××¨ ×›×‘×¨ ×§×™×™× (×œ×¤×™ URL)
            existing = db.query(Article).filter(
                Article.url == article_data["url"]
            ).first()
            
            if existing:
                skipped_count += 1
                continue
            
            # ×¦×•×¨ ××××¨ ×—×“×©
            article = Article(
                title=article_data["title"],
                summary=article_data["summary"],
                content=article_data["content"],
                url=article_data["url"],
                source=article_data["source"],
                category=category.capitalize(),
                image_url=article_data["image_url"],
                thumb_url=article_data["thumb_url"],
                published_at=article_data["published_at"]
            )
            
            db.add(article)
            added_count += 1
            
            # ×”×¦×’ ××™×“×¢
            title_short = article_data["title"][:60] + "..." if len(article_data["title"]) > 60 else article_data["title"]
            print(f"  âœ… {title_short}")
        
        db.commit()
        
        print(f"  ğŸ“Š × ×•×¡×¤×•: {added_count} | ×“×•×œ×’×• (×›×¤×•×œ×™×): {skipped_count}")
        
        return added_count
        
    except Exception as e:
        print(f"  âŒ ×©×’×™××”: {e}")
        db.rollback()
        return 0


def import_by_search(
    db: Session,
    query: str,
    days_back: int = 7,
    limit: int = 10
) -> int:
    """×™×™×‘× ××××¨×™× ×œ×¤×™ ×—×™×¤×•×©"""
    gateway = NewsAPIGateway()
    
    try:
        print(f"\nğŸ” ××—×¤×© ××××¨×™×: '{query}' ({days_back} ×™××™× ××—×•×¨×”)")
        articles = gateway.get_articles_by_topic(query, days_back=days_back, page_size=limit)
        
        added_count = 0
        skipped_count = 0
        
        for article_data in articles:
            # ×‘×“×•×§ ×× ×”××××¨ ×›×‘×¨ ×§×™×™×
            existing = db.query(Article).filter(
                Article.url == article_data["url"]
            ).first()
            
            if existing:
                skipped_count += 1
                continue
            
            # ×¦×•×¨ ××××¨ ×—×“×©
            article = Article(
                title=article_data["title"],
                summary=article_data["summary"],
                content=article_data["content"],
                url=article_data["url"],
                source=article_data["source"],
                category=article_data["category"],
                image_url=article_data["image_url"],
                thumb_url=article_data["thumb_url"],
                published_at=article_data["published_at"]
            )
            
            db.add(article)
            added_count += 1
            
            # ×”×¦×’ ××™×“×¢
            title_short = article_data["title"][:60] + "..." if len(article_data["title"]) > 60 else article_data["title"]
            print(f"  âœ… {title_short}")
        
        db.commit()
        
        print(f"  ğŸ“Š × ×•×¡×¤×•: {added_count} | ×“×•×œ×’×• (×›×¤×•×œ×™×): {skipped_count}")
        
        return added_count
        
    except Exception as e:
        print(f"  âŒ ×©×’×™××”: {e}")
        db.rollback()
        return 0


def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª"""
    print("=" * 80)
    print("ğŸŒ ×™×™×‘×•× ××××¨×™× ×-News API")
    print("=" * 80)
    
    db = SessionLocal()
    total_added = 0
    
    try:
        # ××•×¤×¦×™×” 1: ×™×™×‘× ××××¨×™× ×œ×¤×™ ×§×˜×’×•×¨×™×•×ª
        categories = [
            ("technology", 10),
            ("business", 10),
            ("health", 10),
            ("science", 10),
            ("sports", 10)
        ]
        
        print("\nğŸ“‚ ××™×™×‘× ××××¨×™× ×œ×¤×™ ×§×˜×’×•×¨×™×•×ª:")
        for category, limit in categories:
            count = import_articles_from_category(db, category, limit)
            total_added += count
        
        # ××•×¤×¦×™×” 2: ×™×™×‘× ××××¨×™× ×œ×¤×™ × ×•×©××™× ×¡×¤×¦×™×¤×™×™× (××•×¤×¦×™×•× ×œ×™)
        # topics = [
        #     ("artificial intelligence", 5),
        #     ("climate change", 5),
        #     ("cryptocurrency", 5),
        # ]
        # 
        # print("\n\nğŸ” ××™×™×‘× ××××¨×™× ×œ×¤×™ × ×•×©××™×:")
        # for topic, limit in topics:
        #     count = import_by_search(db, topic, days_back=7, limit=limit)
        #     total_added += count
        
        # ×¡×™×›×•×
        print("\n" + "=" * 80)
        print(f"âœ… ×”×¡×ª×™×™×! ×¡×”\"×› × ×•×¡×¤×• {total_added} ××××¨×™× ×—×“×©×™×")
        print("=" * 80)
        
        # ×”×¦×’ ×¡×˜×˜×™×¡×˜×™×§×” ×›×œ×œ×™×ª
        total_articles = db.query(Article).count()
        print(f"\nğŸ“Š ×¡×”\"×› ××××¨×™× ×‘××¢×¨×›×ª: {total_articles}")
        
        # ×”×¦×’ ×§×˜×’×•×¨×™×•×ª
        categories_in_db = db.query(Article.category).distinct().all()
        categories_list = [c[0] for c in categories_in_db if c[0]]
        print(f"ğŸ“‚ ×§×˜×’×•×¨×™×•×ª: {', '.join(categories_list)}")
        
    except Exception as e:
        print(f"\nâŒ ×©×’×™××” ×›×œ×œ×™×ª: {e}")
        import traceback
        traceback.print_exc()
    finally:
        db.close()


if __name__ == "__main__":
    main()